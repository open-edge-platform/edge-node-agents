# Configuration for telegraf agent
[agent]
  interval = "90s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "2m"
  flush_jitter = "0s"
  precision = "0s"

  ## Log at debug level.
  debug = false
  ## Log only error level messages.
  quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  logtarget = "stderr"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
  # logfile_rotation_interval = "0h"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
  # logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

[[inputs.system]]
  fieldinclude = ["uptime"]

[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
  report_active = false
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = false
  ## Minimal metric set
  fieldinclude = ["usage_idle", "usage_system", "usage_user"]

[[inputs.mem]]
  fieldinclude   = ["available", "buffered", "cached", "free", "total", "used", "used_percent"]

[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs", "proc"]
  fieldinclude   = ["used_percent"]

[[inputs.diskio]]
  device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
  fieldinclude   = ["read_bytes", "write_bytes"]

[[inputs.net]]
  fieldinclude   = ["bytes_recv", "bytes_sent"]

[[inputs.temp]]

#[[inputs.ipmi_sensor]]
#  use_sudo = true
#  interval = "30s"
#  timeout = "20s"
#  metric_version = 2

# [[inputs.smart]]
#   use_sudo = true
#   attributes = true

# [[inputs.intel_powerstat]]
#   package_metrics = ["current_power_consumption", "current_dram_power_consumption", "thermal_design_power"]

# [[inputs.intel_pmu]]
#   ## List of filesystem locations of JSON files that contain PMU event definitions.
#   event_definitions = ["/etc/telegraf/pmu-events/GenuineIntel-6-6A-core.json", "/etc/telegraf/pmu-events/GenuineIntel-6-6A-uncore.json"]
#   ## List of core events measurement entities. There can be more than one core_events sections.
#   [[inputs.intel_pmu.core_events]]
#     ## List of events to be counted. Event names shall match names from event_definitions files.
#     ## Single entry can contain name of the event (case insensitive) augmented with config options and perf modifiers.
#     ## If absent, all core events from provided event_definitions are counted skipping unresolvable ones.
#     events = ["INST_RETIRED.ANY", "CPU_CLK_UNHALTED.THREAD_P"]
#     ## Limits the counting of events to core numbers specified.
#     ## If absent, events are counted on all cores.
#     ## Single "0", multiple "0,1,2" and range "0-2" notation is supported for each array element.
#     ##   example: cores = ["0,2", "4", "12-16"]
#     cores = ["0"]
#     ## Indicator that plugin shall attempt to run core_events.events as a single perf group.
#     ## If absent or set to false, each event is counted individually. Defaults to false.
#     ## This limits the number of events that can be measured to a maximum of available hardware counters per core.
#     ## Could vary depending on type of event, use of fixed counters.
#     # perf_group = false
#     ## Optionally set a custom tag value that will be added to every measurement within this events group.
#     ## Can be applied to any group of events, unrelated to perf_group setting.
#     # events_tag = ""
#   ## List of uncore event measurement entities. There can be more than one uncore_events sections.
#   [[inputs.intel_pmu.uncore_events]]
#     ## List of events to be counted. Event names shall match names from event_definitions files.
#     ## Single entry can contain name of the event (case insensitive) augmented with config options and perf modifiers.
#     ## If absent, all uncore events from provided event_definitions are counted skipping unresolvable ones.
#     events = ["UNC_CHA_CLOCKTICKS", "UNC_CHA_TOR_OCCUPANCY.IA_MISS"]

#     ## Limits the counting of events to specified sockets.
#     ## If absent, events are counted on all sockets.
#     ## Single "0", multiple "0,1" and range "0-1" notation is supported for each array element.
#     ##   example: sockets = ["0-2"]
#     sockets = ["0"]

    ## Indicator that plugin shall provide an aggregated value for multiple units of same type distributed in an uncore.
    ## If absent or set to false, events for each unit are exposed as separate metric. Defaults to false.
    # aggregate_uncore_units = false

    ## Optionally set a custom tag value that will be added to every measurement within this events group.
        # events_tag = ""

# Reads metrics from LVM physical volumes, volume groups, and logical volumes
# [[inputs.lvm]]
#     use_sudo = true

# GPU collection is optionally enabled via control plane
#[[inputs.exec]]
#  commands = ["/opt/telegraf/bin/collect_gpu_metrics.sh"]
#	timeout = "15s"
# 	data_format = "json"
# 	json_strict = true

# Disk information collection
[[inputs.exec]]
    commands = ["/opt/telegraf/bin/collect_disk_info.sh"]
    timeout = "30s"
    data_format = "json_v2"
    name_suffix = "diskmetrics"
    [[inputs.exec.json_v2]]
        [[inputs.exec.json_v2.object]]
            path = "diskSizeTotal"
            [[inputs.exec.json_v2.object.tag]]
                path = "#.tag"
                rename = "device_name"
            [[inputs.exec.json_v2.object.field]]
                path = "#.disk_size_total_bytes"
                type = "int"
        [[inputs.exec.json_v2.object]]
            path = "diskPartUsedTotal"
            [[inputs.exec.json_v2.object.tag]]
                path = "#.tag"
                rename = "device_name"
            [[inputs.exec.json_v2.object.field]]
                path = "#.disk_size_used_partition_bytes"
                type = "int"
        [[inputs.exec.json_v2.object]]
            path = "diskLvmUsedTotal"
            [[inputs.exec.json_v2.object.tag]]
                path = "#.tag"
                rename = "device_name"
            [[inputs.exec.json_v2.object.field]]
                path = "#.disk_size_used_lvm_bytes"
                type = "int"
        [[inputs.exec.json_v2.object]]
            path = "diskAvailTotal"
            [[inputs.exec.json_v2.object.tag]]
                path = "#.tag"
                rename = "device_name"
            [[inputs.exec.json_v2.object.field]]
                path = "#.disk_size_available_bytes"
                type = "int"

# Core, Thread, Hyper threading status metrics
# [[inputs.exec]]
# commands = [" /opt/telegraf/bin/core_metrics.sh"]
#   timeout = "15s"
#   data_format = "json_v2"
#   name_suffix = "coremetrics"
#   [[inputs.exec.json_v2]]
#       [[inputs.exec.json_v2.field]]
#           path = "cores"
#           type = "int"
#       [[inputs.exec.json_v2.field]]
#           path = "threads"
#           type = "int"
#       [[inputs.exec.json_v2.field]]
#           path = "hyper_threading_status"
#           type = "int"

## This plugins requires `/var/run/netns` path to exist
# [[inputs.ethtool]]

# [[inputs.ras]]

# [[inputs.redfish]]
#   ## Redfish API Base URL.
#   address = "http://localhost:8000/redfish/v1"
#   ## Credentials for the Redfish API.
#   username = "root"
#   password = "" 
#   ## System Id to collect data for in Redfish APIs.
#   computer_system_id="1"

[[outputs.opentelemetry]]
  service_address = "unix:///run/platform-observability-agent/platform-observability-agent.sock"
